from __future__ import annotations
from abc import ABC, abstractmethod
import json
from typing import Any, Dict, List, Optional, Type
from pydantic import BaseModel

from app.backend.core.models.prompt import SYSTEM_PROMPT

class ToolSpec(BaseModel):
    """Specification for a tool available to the LLM."""

    name: str
    description: Optional[str] = None
    args_schema: Dict[str, Any]

class LLM(ABC):
    """
    Abstract base class for all LLM providers.

    Responsibilities:
    - Manage registration of decorated tools (functions callable by the LLM)
    - Expose tool specifications for prompt injection or native tool-calling
    - Define a consistent interface for initializing the provider client
      and generating responses
    """

    def __init__(self, model_name: str):
        self.model_name = model_name
        self.client = self.init_client()
        self._tools: Dict[str, ToolSpec] = {}
        self._tool_runners: Dict[str, Any] = {}

    @abstractmethod
    def init_client(self):
        """Initialize the provider client (e.g., Mistral, OpenAI, etc.)."""
        raise NotImplementedError

    @abstractmethod
    def generate(self, user_input: str, system_prompt: Optional[str] = None) -> str:
        """Return the text (or JSON string) generated by the LLM."""
        raise NotImplementedError

    def register_tool(
        self,
        name: str,
        args_model: Type[BaseModel],
        runner_fn,
        description: Optional[str] = None,
    ):
        """
        Register a new tool so that it can be referenced and executed by the LLM.

        Args:
            name: The unique name of the tool.
            args_model: A Pydantic model defining the expected input arguments.
            runner_fn: The Python function implementing the tool logic.
            description: Optional short description of the tool.
        """
        if name in self._tools:
            raise ValueError(f"Tool '{name}' is already registered.")
        spec = ToolSpec(
            name=name,
            description=description,
            args_schema=args_model.model_json_schema(),
        )
        self._tools[name] = spec
        self._tool_runners[name] = {"fn": runner_fn, "args_model": args_model}
    
    def register_decorated_tool(self, func):
        name = getattr(func, "__tool_name__", None)
        args_model = getattr(func, "__tool_args_model__", None)
        desc = getattr(func, "__tool_description__", None)
        if not (name and args_model):
            raise ValueError(f"Function {getattr(func, '__name__', func)} is not decorated with @tool")
        self.register_tool(name=name, args_model=args_model, runner_fn=func, description=desc)

    def get_tools_spec(self) -> List[Dict[str, Any]]:
        """
        Return a serializable list of tool specifications.

        This can be injected into a system prompt or mapped to a native
        'tools' format for providers that support function calling.
        """
        return [spec.model_dump() for spec in self._tools.values()]

    def has_native_tool_calling(self) -> bool:
        """
        Override this in subclasses if the provider supports native
        tool/function calling (e.g., OpenAI function calling, Mistral tools API).
        """
        return False

    def run_tool(self, name: str, args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute a registered tool by name, validating arguments against its
        associated Pydantic model before execution.

        Args:
            name: The name of the registered tool.
            args: The input arguments as a dictionary.

        Returns:
            The result of the tool execution.
        """
        if name not in self._tool_runners:
            raise ValueError(f"Unknown tool '{name}'")
        entry = self._tool_runners[name]
        model = entry["args_model"]
        fn = entry["fn"]
        parsed = model(**args)
        return fn(parsed)

    def _compose_system_prompt(self, system_prompt: Optional[str]) -> str:
        """
        Build the complete system prompt by combining the base SYSTEM_PROMPT
        with the currently registered tool specifications.

        The placeholder '{{TOOLS_SPEC}}' in the base prompt will be replaced
        with a JSON list describing all available tools.

        Args:
            system_prompt: An optional custom prompt to override the default.

        Returns:
            A string representing the final system prompt to send to the LLM.
        """
        base = system_prompt or SYSTEM_PROMPT
        tools_json = json.dumps(self.get_tools_spec(), ensure_ascii=False)
        return base.replace("{{TOOLS_SPEC}}", tools_json)
